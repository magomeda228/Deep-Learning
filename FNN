Describe lab work FNN

В ходе выполнения работы были реализованы различные методы для решения задач регрессии и классификации с использованием линейных моделей, Ridge-регрессии и нейронных сетей.
Оценка качества моделей проводилась на основе метрик MSE и функции потерь (loss).

Были получены следующие ключевые выводы:

Линейная модель:

Без предварительной нормализации данных результаты работы модели были менее стабильными, с высоким значением MSE и Loss.
После нормализации целевой переменной и признаков MSE и Loss функции значительно снизились, что позволило улучшить качество модели и ускорить сходимость.
Регуляризация и оптимизация:

Использование Ridge-регрессии (L2 регуляризация) позволило достичь низкого значения MSE по сравнению с константной моделью, что подтвердило её эффективность.
В случае с оптимизатором SGD с моментумом, модель быстрее сходилась, при этом функции потерь и MSE стабильно снижались в процессе обучения. Время обучения составило 4,5 секунды.
Оптимизатор Adam показал стабильное снижение MSE, но время обучения увеличилось (0,5 секунды дольше, чем у SGD).
Нейронные сети:

Увеличение числа скрытых нейронов с 128 до 256 улучшило модель, но время обучения также увеличилось. Модель продолжала показывать хорошие результаты на обучении и валидации с низкими значениями MSE и Loss.
Добавление второго скрытого слоя улучшило модель, но время обучения возросло в 1,5 раза, при этом MSE продолжал снижаться и стабилизироваться.
Использование Dropout значительно улучшило результаты модели, снизив MSE до < 0.1 и сделав функцию потерь более стабильной. Важно, что разница между обучением и валидацией увеличилась, что указывает на улучшение обобщающей способности модели.

Гиперпараметры:

Learning rate (lr) = 1e-4 оказался оптимальным значением для стабильного обучения с минимальными значениями MSE и Loss на валидации.
Weight decay = 1e-5 показал лучшие результаты, так как модель не переобучалась. После увеличения значения weight decay до 0, наблюдался резкий рост функции потерь, что подтверждает важность правильного выбора коэффициента регуляризации.

Заключение: Работа с нейронными сетями, правильный выбор гиперпараметров (learning rate, weight decay) и использование методов регуляризации, таких как Dropout, улучшили сходимость и точность модели.
Нормализация данных и целевой переменной позволила уменьшить абсолютные значения MSE и Loss, а также улучшить стабильность модели как на обучении, так и на валидации.
